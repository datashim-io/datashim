apiVersion: apps/v1
kind: Deployment
metadata:
  name: text-generation-inference
  labels:
    run: text-generation-inference
spec:
  replicas: 1
  selector:
    matchLabels:
      run: text-generation-inference
  template:
    metadata:
      labels:
        run: text-generation-inference
        dataset.0.id: "model-weights"
        dataset.0.useas: "mount"
    spec:
      containers:
        - name: text-generation-inference
          image: ghcr.io/huggingface/text-generation-inference:1.3.4
          env:
            - name: RUST_BACKTRACE
              value: "1"
          command:
            - "text-generation-launcher"
            - "--model-id"
            - "/mnt/datasets/model-weights/my-model/"
            - "--sharded"
            - "false"
            - "--port"
            - "8080"
            - "--huggingface-hub-cache"
            - "/tmp"
          resources:
            limits:
              cpu: "8"
              memory: "8Gi"
          ports:
            - containerPort: 8080
              name: http
      restartPolicy: Always