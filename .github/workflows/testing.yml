name: Test on KinD
on:
  pull_request:
    types: [ready_for_review, review_requested, opened, reopened, synchronize]

jobs:
  integration-test:
    runs-on: ubuntu-latest
    steps:
      - name: Clone Datashim
        uses: actions/checkout@v2
      - name: Build components
        run: |
          cd build-tools
          ./build_components.sh
      - name: Make Datashim manifests
        run: make manifests
      - name: Update manifests to use local images
        run: "sed -i 's/Always/IfNotPresent/g' release-tools/manifests/dlf.yaml"
      - name: Create k8s Kind Cluster
        uses: helm/kind-action@v1.4.0
      - name: Import built images in KinD Cluster
        run: |
          kind load docker-image -n chart-testing quay.io/datashim-io/dataset-operator:latest
          kind load docker-image -n chart-testing quay.io/datashim-io/generate-keys:latest
      - name: Install Datashim
        run: make deployment
      - name: Install MinIO
        run: |
          # Start MinIO
          docker run -d -p 9000:9000 -p 9001:9001 \
            -e "MINIO_ACCESS_KEY=ACCESS_KEY" \
            -e "MINIO_SECRET_KEY=SECRET_KEY" \
            quay.io/minio/minio server /data --console-address ":9001"
          # Install AWS Cli
          pip install awscli
          # Configure AWS CLI
          aws configure set aws_access_key_id --profile=minio ACCESS_KEY
          aws configure set aws_secret_access_key --profile=minio SECRET_KEY
          # Create bucket
          aws s3api --profile minio --endpoint http://127.0.0.1:9000 create-bucket --bucket first.bucket
      - name: Create S3 Secret
        run: |
         kubectl create secret generic s3-secret \
          --from-literal=accessKeyID=ACCESS_KEY \
          --from-literal=secretAccessKey=SECRET_KEY
      - name: Create sample Dataset
        run: |
          cat <<EOF | kubectl apply -f -
          apiVersion: com.ie.ibm.hpsys/v1alpha1
          kind: Dataset
          metadata:
            name: example-dataset
          spec:
            local:
              type: "COS"
              secret-name: "s3-secret"
              endpoint: "http://s3.default.svc"
              bucket: "first.bucket"
          EOF
      - name: Write to Dataset
        run: |
          cat <<EOF | kubectl apply -f -
          apiVersion: batch/v1
          kind: Job
          metadata:
            name: ds-write
          spec:
            template:
              spec:
                volumes:
                - name: "example-dataset"
                  persistentVolumeClaim:
                    claimName: "example-dataset"
                containers:
                - command: ["/bin/sh"]
                  args: ["-c", "echo 'Some file contents' > /mnt/datashim/test.txt"]
                  image: busybox
                  name: busybox
                  volumeMounts:
                    - mountPath: "/mnt/datashim" 
                      name: "example-dataset"
                restartPolicy: Never
            backoffLimit: 1
          EOF
          kubectl wait --for=condition=complete job/ds-write --timeout=30s
      - name: Read from Dataset
        run: |
          cat <<EOF | kubectl apply -f -
          apiVersion: batch/v1
          kind: Job
          metadata:
            name: ds-read
          spec:
            template:
              spec:
                volumes:
                - name: "example-dataset"
                  persistentVolumeClaim:
                    claimName: "example-dataset"
                containers:
                - command: ["/bin/sh"]
                  args: ["-c", "cat /mnt/datashim/test.txt"]
                  image: busybox
                  name: busybox
                  volumeMounts:
                    - mountPath: "/mnt/datashim" 
                      name: "example-dataset"
                restartPolicy: Never
            backoffLimit: 1
          EOF
          kubectl wait --for=condition=complete job/ds-read --timeout=30s
