---
name: Test on KinD
on:
  pull_request:
    types: [ready_for_review, review_requested, opened, reopened, synchronize]

jobs:
  integration-test:
    runs-on: ubuntu-latest
    steps:
      - name: Clone Datashim
        uses: actions/checkout@v2
      - name: Build components
        run: |
          cd build-tools
          ./build_components.sh
      - name: Make Datashim manifests
        run: make manifests
      - name: Update manifests to use local images
        run: "sed -i 's/Always/IfNotPresent/g' release-tools/manifests/dlf.yaml"
      - name: Create k8s Kind Cluster
        uses: helm/kind-action@v1.4.0
      - name: Install and configure MinIO
        run: |
          kubectl create -f ci/minio.yaml
          kubectl wait --for=condition=ready pod/minio --timeout=1m
          kubectl create -f ci/configure-minio.yaml
          kubectl wait --for=condition=complete job/configure-minio --timeout=2m
      - name: Create S3 Secret
        run: |
         kubectl create secret generic s3-secret \
          --from-literal=accessKeyID=ACCESS_KEY \
          --from-literal=secretAccessKey=SECRET_KEY
      - name: Import built images in KinD Cluster
        run: |
          kind load docker-image -n chart-testing quay.io/datashim-io/dataset-operator:latest
          kind load docker-image -n chart-testing quay.io/datashim-io/generate-keys:latest
      - name: Install Datashim
        run: make deployment
      - name: Create sample Dataset
        run: |
          cat <<EOF | kubectl apply -f -
          apiVersion: com.ie.ibm.hpsys/v1alpha1
          kind: Dataset
          metadata:
            name: example-dataset
          spec:
            local:
              type: "COS"
              secret-name: "s3-secret"
              endpoint: "http://minio.default.svc:9000"
              bucket: "first.bucket"
          EOF
      - name: Write to Dataset
        run: |
          cat <<EOF | kubectl apply -f -
          apiVersion: batch/v1
          kind: Job
          metadata:
            name: ds-write
          spec:
            template:
              spec:
                volumes:
                - name: "example-dataset"
                  persistentVolumeClaim:
                    claimName: "example-dataset"
                containers:
                - command: ["/bin/sh"]
                  args: ["-c", "echo 'Some file contents' > /mnt/datashim/test.txt"]
                  image: busybox
                  name: busybox
                  volumeMounts:
                    - mountPath: "/mnt/datashim" 
                      name: "example-dataset"
                restartPolicy: Never
            backoffLimit: 1
          EOF
          kubectl wait --for=condition=complete job/ds-write --timeout=2m
      - name: Read from Dataset
        run: |
          cat <<EOF | kubectl apply -f -
          apiVersion: batch/v1
          kind: Job
          metadata:
            name: ds-read
          spec:
            template:
              spec:
                volumes:
                - name: "example-dataset"
                  persistentVolumeClaim:
                    claimName: "example-dataset"
                containers:
                - command: ["/bin/sh"]
                  args: ["-c", "cat /mnt/datashim/test.txt"]
                  image: busybox
                  name: busybox
                  volumeMounts:
                    - mountPath: "/mnt/datashim" 
                      name: "example-dataset"
                restartPolicy: Never
            backoffLimit: 1
          EOF
          kubectl wait --for=condition=complete job/ds-read --timeout=2m
